{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import torch\n",
    "import random\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with h5py.File('data/KdV_train_1024_default.h5', 'r') as f:\n",
    "#     traj_train = torch.tensor(f['train']['pde_140-256'][:], dtype=torch.float32)\n",
    "# with h5py.File('data/KdV_valid_1024_default.h5', 'r') as f:\n",
    "#     traj_valid = torch.tensor(f['valid']['pde_140-256'][:], dtype=torch.float32)\n",
    "# with h5py.File('data/KdV_test_4096_default.h5', 'r') as f:\n",
    "#     traj_test = torch.tensor(f['test']['pde_140-256'][:], dtype=torch.float32)\n",
    "\n",
    "class args:\n",
    "    equation = 'KdV'\n",
    "\n",
    "class Traj_dataset:\n",
    "    traj_train = None\n",
    "    traj_valid = None\n",
    "    traj_test = None\n",
    "\n",
    "with h5py.File(f'data/{args.equation}_train_1024_default.h5', 'r') as f:\n",
    "    Traj_dataset.traj_train = torch.tensor(f['train']['pde_140-256'][:], dtype=torch.float32)[:, :131]\n",
    "with h5py.File(f'data/{args.equation}_valid_1024_default.h5', 'r') as f:\n",
    "    Traj_dataset.traj_valid = torch.tensor(f['valid']['pde_140-256'][:], dtype=torch.float32)[:, :131]\n",
    "with h5py.File(f'data/{args.equation}_test_4096_default.h5', 'r') as f:\n",
    "    Traj_dataset.traj_test = torch.tensor(f['test']['pde_140-256'][:], dtype=torch.float32)[:, :131]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Tuple\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LpLoss(object):\n",
    "    def __init__(self, d=2, p=2, size_average=True, reduction=True):\n",
    "        super(LpLoss, self).__init__()\n",
    "\n",
    "        #Dimension and Lp-norm type are postive\n",
    "        assert d > 0 and p > 0\n",
    "\n",
    "        self.d = d\n",
    "        self.p = p\n",
    "        self.reduction = reduction\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def abs(self, x, y):\n",
    "        num_examples = x.size()[0]\n",
    "\n",
    "        #Assume uniform mesh\n",
    "        h = 1.0 / (x.size()[1] - 1.0) if x.size()[1] > 1 else 1.0\n",
    "\n",
    "        all_norms = (h**(self.d/self.p))*torch.norm(x.view(num_examples,-1) - y.view(num_examples,-1), self.p, 1)\n",
    "\n",
    "        if self.reduction:\n",
    "            if self.size_average:\n",
    "                return torch.mean(all_norms)\n",
    "            else:\n",
    "                return torch.sum(all_norms)\n",
    "\n",
    "        return all_norms\n",
    "\n",
    "    def rel(self, x, y):\n",
    "        num_examples = x.size()[0]\n",
    "\n",
    "        diff_norms = torch.norm(x.reshape(num_examples,-1) - y.reshape(num_examples,-1), self.p, 1)\n",
    "        y_norms = torch.norm(y.reshape(num_examples,-1), self.p, 1)\n",
    "\n",
    "        if self.reduction:\n",
    "            if self.size_average:\n",
    "                return torch.mean(diff_norms/y_norms)\n",
    "            else:\n",
    "                return torch.sum(diff_norms/y_norms)\n",
    "\n",
    "        return diff_norms/y_norms\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        return self.rel(x, y)\n",
    "\n",
    "def compute_metrics(y, y_pred, d=1) :\n",
    "    L2_func = LpLoss(d=d, p=2, reduction=False)\n",
    "    if y.shape != y_pred.shape :\n",
    "        raise NotImplementedError\n",
    "    l2 = L2_func.abs(y, y_pred) # [bs]\n",
    "    relative_l2 = L2_func.rel(y, y_pred) # [bs]\n",
    "    mse = F.mse_loss(y_pred, y, reduction='none') # [bs]\n",
    "    mse = mse.mean(dim=tuple(range(1, mse.ndim)))\n",
    "    return l2, relative_l2, mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "lr = 0.001\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:05<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256, 6.253170013427734\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from neuralop.models import FNO\n",
    "from tqdm import tqdm\n",
    "\n",
    "from acquisition.acquirers import select\n",
    "\n",
    "def train(X_train, Y_train):\n",
    "    model = FNO(n_modes=(256, ), hidden_channels=64,\n",
    "                    in_channels=1, out_channels=1)\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(X_train, Y_train)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for x, y in dataloader:\n",
    "            # x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def test(model):\n",
    "    X_test = Traj_dataset.traj_test[:,0,:].unsqueeze(1).to(device)\n",
    "    Y_test = Traj_dataset.traj_test[:,-1,:].unsqueeze(1).to(device)\n",
    "\n",
    "    testset = torch.utils.data.TensorDataset(X_test, Y_test)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    Y_test_pred = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in testloader:\n",
    "            # x, y = x.to(device), y.to(device)\n",
    "            y_pred = model(x)\n",
    "            Y_test_pred.append(y_pred)\n",
    "        Y_test_pred = torch.cat(Y_test_pred, dim=0).to(Y_test.device)\n",
    "    \n",
    "    metrics = compute_metrics(Y_test, Y_test_pred, d=1)\n",
    "    return metrics\n",
    "\n",
    "\n",
    "initial_datasize=256\n",
    "batch_acquire=32\n",
    "num_acquire=1\n",
    "ensemble_size = 5\n",
    "\n",
    "results = {'datasize': [], 'rel_l2': []}\n",
    "\n",
    "X = Traj_dataset.traj_train[:,0].unsqueeze(1).to(device)\n",
    "Y = Traj_dataset.traj_train[:,-1].unsqueeze(1).to(device)\n",
    "\n",
    "train_idxs = torch.arange(initial_datasize, device=device)\n",
    "pool_idxs = torch.arange(initial_datasize, X.shape[0], device=device)\n",
    "\n",
    "X_train = X[train_idxs]\n",
    "Y_train = Y[train_idxs]\n",
    "\n",
    "X_pool = X[pool_idxs]\n",
    "\n",
    "ensemble = [train(X_train, Y_train) for _ in tqdm(range(ensemble_size))]\n",
    "\n",
    "results['datasize'].append(train_idxs.shape[0])\n",
    "rel_l2_list = [test(model)[1].mean().item() for model in ensemble]\n",
    "results['rel_l2'].append(torch.mean(torch.tensor(rel_l2_list)).item())\n",
    "print(f'{results[\"datasize\"][-1]}, {results[\"rel_l2\"][-1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MeanModel(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(MeanModel, self).__init__()\n",
    "        self.model = model\n",
    "    def forward(self, x):\n",
    "        y = self.model(x)\n",
    "        y = torch.mean(y, dim=tuple(range(1, y.ndim)))\n",
    "        y = y.unsqueeze(1)\n",
    "        return y\n",
    "    \n",
    "Y_mean_train = Y_train.mean(dim=tuple(range(1, Y_train.ndim))).unsqueeze(1)\n",
    "\n",
    "\n",
    "ensemble_mean = [MeanModel(model) for model in ensemble]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([250, 612,  41,  24, 154, 233, 420, 592, 500, 644, 201, 184,  79, 681,\n",
      "        244, 106,  63, 360, 397, 552, 571, 604, 547, 219, 731, 246, 171, 524,\n",
      "        415, 323, 633, 725], device='cuda:0')\n",
      "tensor([250,  41, 612, 121,  24, 681, 244, 753, 154, 428, 233, 600, 749, 500,\n",
      "        313, 739, 441, 420, 592, 548, 662, 731, 219, 363, 342, 339, 482, 360,\n",
      "        725, 524, 567, 558], device='cuda:0')\n",
      "tensor([250,  41, 612, 121,  24, 681, 244, 753, 428, 154, 548, 749, 441, 233,\n",
      "        600, 313, 549, 464, 739, 461, 308, 420, 647, 311, 397, 727, 592, 717,\n",
      "        500, 662, 532,  74], device='cuda:0')\n",
      "tensor([250,  41, 612, 121,  24, 681, 244, 753, 428, 154, 548, 749, 441, 233,\n",
      "        600, 313, 549, 464, 739, 461, 308, 420, 647, 311, 397, 727, 592, 717,\n",
      "        500, 662, 532,  74], device='cuda:0')\n",
      "tensor([250,  41, 612, 121,  24, 681, 244, 753, 428, 154, 548, 749, 441, 233,\n",
      "        600, 313, 549, 464, 739, 461, 308, 420, 647, 311, 397, 727, 592, 717,\n",
      "        500, 662, 532,  74], device='cuda:0')\n",
      "---\n",
      "tensor([250,  41, 612, 121,  24, 681, 244, 753, 428, 154, 548, 749, 441, 233,\n",
      "        600, 313, 549, 464, 739, 461, 647, 311, 727, 592, 308, 420, 397, 662,\n",
      "        717, 500, 532,  74], device='cuda:0')\n",
      "tensor([250,  41, 612, 121,  24, 681, 244, 753, 428, 154, 548, 749, 441, 233,\n",
      "        600, 313, 549, 464, 739, 461, 308, 420, 647, 311, 397, 727, 592, 717,\n",
      "        500, 662, 532,  74], device='cuda:0')\n",
      "tensor([250,  41, 612, 121,  24, 681, 244, 753, 428, 154, 548, 749, 441, 233,\n",
      "        600, 313, 549, 464, 739, 461, 308, 420, 647, 311, 397, 727, 592, 717,\n",
      "        500, 662, 532,  74], device='cuda:0')\n",
      "tensor([250,  41, 612, 121,  24, 681, 244, 753, 428, 154, 548, 749, 441, 233,\n",
      "        600, 313, 549, 464, 739, 461, 308, 420, 647, 311, 397, 727, 592, 717,\n",
      "        500, 662, 532,  74], device='cuda:0')\n",
      "tensor([250,  41, 612, 121,  24, 681, 244, 753, 428, 154, 548, 749, 441, 233,\n",
      "        600, 313, 549, 464, 739, 461, 308, 311, 420, 647, 397, 727, 592, 717,\n",
      "        500, 662, 532,  74], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from bmdal_reg.bmdal.feature_data import TensorFeatureData\n",
    "from bmdal_reg.bmdal.algorithms import select_batch\n",
    "\n",
    "train_data = TensorFeatureData(X_train)\n",
    "pool_data = TensorFeatureData(X_pool)\n",
    "for bait_sigma in [1e-4, 1e-3, 1e-2, 1e-1, 1]:\n",
    "    new_idxs, _ = select_batch(batch_size=32, models=ensemble_mean[:2], \n",
    "                               data={'train': train_data, 'pool': pool_data}, y_train=Y_mean_train,\n",
    "                               selection_method='bait', sel_with_train=False, bait_sigma=bait_sigma,\n",
    "                               base_kernel='predictions', kernel_transforms=[]) #[('rp', [5])])\n",
    "    print(new_idxs)\n",
    "# new_idxs, _ = select_batch(batch_size=32, models=ensemble_mean[:2], \n",
    "#                            data={'train': train_data, 'pool': pool_data}, y_train=Y_mean_train,\n",
    "#                            selection_method='maxdiag', sel_with_train=False,\n",
    "#                            base_kernel='predictions', kernel_transforms=[]) #[('rp', [5])])\n",
    "# print(new_idxs)\n",
    "\n",
    "print('---')\n",
    "\n",
    "for maxdet_sigma in [1e-4, 1e-3, 1e-2, 1e-1, 1]:\n",
    "    new_idxs, _ = select_batch(batch_size=32, models=ensemble_mean[:2], \n",
    "                            data={'train': train_data, 'pool': pool_data}, y_train=Y_mean_train,\n",
    "                            selection_method='maxdet', sel_with_train=False, maxdet_sigma=maxdet_sigma,\n",
    "                            base_kernel='predictions', kernel_transforms=[]) #[('rp', [5])])\n",
    "    print(new_idxs)\n",
    "# new_idxs, _ = select_batch(batch_size=32, models=ensemble_mean[:2], \n",
    "#                            data={'train': train_data, 'pool': pool_data}, y_train=Y_mean_train,\n",
    "#                            selection_method='lcmd', sel_with_train=False,\n",
    "#                            base_kernel='predictions', kernel_transforms=[]) #[('rp', [5])])\n",
    "# print(new_idxs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m train_data \u001b[38;5;241m=\u001b[39m TensorFeatureData(X_train)\n\u001b[1;32m      5\u001b[0m pool_data \u001b[38;5;241m=\u001b[39m TensorFeatureData(X_pool)\n\u001b[0;32m----> 6\u001b[0m new_idxs, _ \u001b[38;5;241m=\u001b[39m \u001b[43mselect_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensemble\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpool\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpool_data\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mselection_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbait\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msel_with_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbait_sigma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mbase_kernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpredictions\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_transforms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#[('rp', [5])])\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(new_idxs)\n",
      "File \u001b[0;32m~/home/lupi/bmdal_reg/bmdal/algorithms.py:87\u001b[0m, in \u001b[0;36mselect_batch\u001b[0;34m(batch_size, models, data, y_train, base_kernel, kernel_transforms, selection_method, precomp_batch_size, nn_batch_size, **config)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03mThis method allows to apply the methods from the paper for selecting a batch of indices from the pool set,\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03mwhere the base kernel, kernel transformations and selection method can be easily configured.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03mTimes are measured in seconds.\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     86\u001b[0m bs \u001b[38;5;241m=\u001b[39m BatchSelectorImpl(models, data, y_train)\n\u001b[0;32m---> 87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_kernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_kernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_transforms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel_transforms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselection_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mselection_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecomp_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecomp_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnn_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnn_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m                 \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/home/lupi/bmdal_reg/bmdal/algorithms.py:354\u001b[0m, in \u001b[0;36mBatchSelectorImpl.select\u001b[0;34m(self, base_kernel, kernel_transforms, selection_method, batch_size, precomp_batch_size, nn_batch_size, **config)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnknown kernel transform \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtfm_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_models):\n\u001b[0;32m--> 354\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_tfm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPrecomputeTransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecomp_batch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_cuda_synchronize\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    357\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39msynchronize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/home/lupi/bmdal_reg/bmdal/algorithms.py:127\u001b[0m, in \u001b[0;36mBatchSelectorImpl.apply_tfm\u001b[0;34m(self, model_idx, tfm)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03mInternal method that applies a transformation to all Features objects (train/pool)\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;124;03mfor the model with index model_idx.\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m:param model_idx: Index of the model to apply transformations to\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m:param tfm: Transformation to apply to the Features.\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures:\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures[key][model_idx] \u001b[38;5;241m=\u001b[39m \u001b[43mtfm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/home/lupi/bmdal_reg/bmdal/features.py:383\u001b[0m, in \u001b[0;36mPrecomputeTransform.__call__\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    382\u001b[0m     features \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mbatched(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size)\n\u001b[0;32m--> 383\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msimplify()\n",
      "File \u001b[0;32m~/home/lupi/bmdal_reg/bmdal/features.py:37\u001b[0m, in \u001b[0;36mFeatures.precompute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprecompute\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeatures\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     33\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m    :return: Returns a Features object where the feature map is precomputed on the feature data,\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m    i.e., some methods should be faster to evaluate on the precomputed Features object.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m     fm, fd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_map\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiag \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiag \u001b[38;5;241m=\u001b[39m fm\u001b[38;5;241m.\u001b[39mget_kernel_matrix_diag(fd)\n",
      "File \u001b[0;32m~/home/lupi/bmdal_reg/bmdal/feature_maps.py:120\u001b[0m, in \u001b[0;36mFeatureMap.precompute\u001b[0;34m(self, feature_data, idxs)\u001b[0m\n\u001b[1;32m    117\u001b[0m idxs \u001b[38;5;241m=\u001b[39m Indexes(feature_data\u001b[38;5;241m.\u001b[39mget_n_samples(), idxs)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mallow_precompute_features:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;66;03m# simply compute the feature matrix and apply an identity feature map to it\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m IdentityFeatureMap(n_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features), \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfeature_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midxs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;66;03m# use another precomputation method that can be overridden by a subclass.\u001b[39;00m\n\u001b[1;32m    123\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecompute_soft_(sub_data, sub_idxs) \u001b[38;5;28;01mfor\u001b[39;00m sub_idxs, sub_data \u001b[38;5;129;01min\u001b[39;00m feature_data\u001b[38;5;241m.\u001b[39miterate(idxs)]\n",
      "File \u001b[0;32m~/home/lupi/bmdal_reg/bmdal/feature_maps.py:57\u001b[0m, in \u001b[0;36mDataTransform.__call__\u001b[0;34m(self, feature_data, idxs)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03mMethod to apply the transformation to (a subset of) the given feature data.\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03mSubclasses should not override this method, but override forward() instead.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m:return: Returns a FeatureData object.\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     56\u001b[0m idxs \u001b[38;5;241m=\u001b[39m Indexes(feature_data\u001b[38;5;241m.\u001b[39mget_n_samples(), idxs)\n\u001b[0;32m---> 57\u001b[0m pieces \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(sub_data, sub_idxs)\n\u001b[1;32m     58\u001b[0m           \u001b[38;5;28;01mfor\u001b[39;00m sub_idxs, sub_data \u001b[38;5;129;01min\u001b[39;00m feature_data\u001b[38;5;241m.\u001b[39miterate(idxs)]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ConcatFeatureData(pieces) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pieces) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m pieces[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/home/lupi/bmdal_reg/bmdal/feature_maps.py:57\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03mMethod to apply the transformation to (a subset of) the given feature data.\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03mSubclasses should not override this method, but override forward() instead.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m:return: Returns a FeatureData object.\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     56\u001b[0m idxs \u001b[38;5;241m=\u001b[39m Indexes(feature_data\u001b[38;5;241m.\u001b[39mget_n_samples(), idxs)\n\u001b[0;32m---> 57\u001b[0m pieces \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub_idxs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m           \u001b[38;5;28;01mfor\u001b[39;00m sub_idxs, sub_data \u001b[38;5;129;01min\u001b[39;00m feature_data\u001b[38;5;241m.\u001b[39miterate(idxs)]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ConcatFeatureData(pieces) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pieces) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m pieces[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/home/lupi/bmdal_reg/bmdal/feature_maps.py:104\u001b[0m, in \u001b[0;36mFeatureMap.forward\u001b[0;34m(self, feature_data, idxs)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, feature_data: FeatureData, idxs: Indexes) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FeatureData:\n\u001b[1;32m     96\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;124;03m    Implements the forward() method from DataTransform,\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m    which in this case computes the feature matrix wrapped in TensorFeatureData.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m    :return: Returns a TensorFeatureData object containing the feature matrix.\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m TensorFeatureData(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_feature_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midxs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/home/lupi/bmdal_reg/bmdal/feature_maps.py:181\u001b[0m, in \u001b[0;36mFeatureMap.get_feature_matrix\u001b[0;34m(self, feature_data, idxs)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03mReturns the feature matrix obtained by applying this feature map to feature_data[idxs].\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03mThis method can only be used if get_feature_matrix_impl_() is implemented,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m:return: Feature matrix as torch.Tensor of shape n_samples x n_features\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    180\u001b[0m idxs \u001b[38;5;241m=\u001b[39m Indexes(feature_data\u001b[38;5;241m.\u001b[39mget_n_samples(), idxs)\n\u001b[0;32m--> 181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch_cat([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_feature_matrix_impl_(sub_data, sub_idxs)\n\u001b[1;32m    182\u001b[0m                   \u001b[38;5;28;01mfor\u001b[39;00m sub_idxs, sub_data \u001b[38;5;129;01min\u001b[39;00m feature_data\u001b[38;5;241m.\u001b[39miterate(idxs)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/home/lupi/bmdal_reg/bmdal/feature_maps.py:181\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03mReturns the feature matrix obtained by applying this feature map to feature_data[idxs].\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03mThis method can only be used if get_feature_matrix_impl_() is implemented,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m:return: Feature matrix as torch.Tensor of shape n_samples x n_features\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    180\u001b[0m idxs \u001b[38;5;241m=\u001b[39m Indexes(feature_data\u001b[38;5;241m.\u001b[39mget_n_samples(), idxs)\n\u001b[0;32m--> 181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch_cat([\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_feature_matrix_impl_\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub_idxs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m                   \u001b[38;5;28;01mfor\u001b[39;00m sub_idxs, sub_data \u001b[38;5;129;01min\u001b[39;00m feature_data\u001b[38;5;241m.\u001b[39miterate(idxs)], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/home/lupi/bmdal_reg/bmdal/feature_maps.py:739\u001b[0m, in \u001b[0;36mSequentialFeatureMap.get_feature_matrix_impl_\u001b[0;34m(self, feature_data, idxs)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_feature_matrix_impl_\u001b[39m(\u001b[38;5;28mself\u001b[39m, feature_data: FeatureData, idxs: Indexes) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 739\u001b[0m     feature_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtfms\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midxs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# or: SubsetFeatureData(feature_data, idxs)\u001b[39;00m\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m tfm \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtfms[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[1;32m    741\u001b[0m         feature_data \u001b[38;5;241m=\u001b[39m tfm(feature_data)\n",
      "File \u001b[0;32m~/home/lupi/bmdal_reg/bmdal/feature_maps.py:57\u001b[0m, in \u001b[0;36mDataTransform.__call__\u001b[0;34m(self, feature_data, idxs)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03mMethod to apply the transformation to (a subset of) the given feature data.\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03mSubclasses should not override this method, but override forward() instead.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m:return: Returns a FeatureData object.\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     56\u001b[0m idxs \u001b[38;5;241m=\u001b[39m Indexes(feature_data\u001b[38;5;241m.\u001b[39mget_n_samples(), idxs)\n\u001b[0;32m---> 57\u001b[0m pieces \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(sub_data, sub_idxs)\n\u001b[1;32m     58\u001b[0m           \u001b[38;5;28;01mfor\u001b[39;00m sub_idxs, sub_data \u001b[38;5;129;01min\u001b[39;00m feature_data\u001b[38;5;241m.\u001b[39miterate(idxs)]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ConcatFeatureData(pieces) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pieces) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m pieces[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/home/lupi/bmdal_reg/bmdal/feature_maps.py:57\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03mMethod to apply the transformation to (a subset of) the given feature data.\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03mSubclasses should not override this method, but override forward() instead.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m:return: Returns a FeatureData object.\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     56\u001b[0m idxs \u001b[38;5;241m=\u001b[39m Indexes(feature_data\u001b[38;5;241m.\u001b[39mget_n_samples(), idxs)\n\u001b[0;32m---> 57\u001b[0m pieces \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub_idxs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m           \u001b[38;5;28;01mfor\u001b[39;00m sub_idxs, sub_data \u001b[38;5;129;01min\u001b[39;00m feature_data\u001b[38;5;241m.\u001b[39miterate(idxs)]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ConcatFeatureData(pieces) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pieces) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m pieces[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/home/lupi/bmdal_reg/bmdal/layer_features.py:96\u001b[0m, in \u001b[0;36mModelPredictionsTransform.forward\u001b[0;34m(self, feature_data, idxs)\u001b[0m\n\u001b[1;32m     93\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     95\u001b[0m y \u001b[38;5;241m=\u001b[39m model(X)  \u001b[38;5;66;03m# implicitly calls hooks that were set by l.before_forward()\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs\n\u001b[1;32m     98\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain(old_training)\n\u001b[1;32m    100\u001b[0m ys\u001b[38;5;241m.\u001b[39mappend(y)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from bmdal_reg.bmdal.feature_data import TensorFeatureData\n",
    "from bmdal_reg.bmdal.algorithms import select_batch\n",
    "\n",
    "train_data = TensorFeatureData(X_train)\n",
    "pool_data = TensorFeatureData(X_pool)\n",
    "new_idxs, _ = select_batch(batch_size=50, models=ensemble[:2], \n",
    "                           data={'train': train_data, 'pool': pool_data}, y_train=Y_train,\n",
    "                           selection_method='bait', sel_with_train=False, bait_sigma=1e-3,\n",
    "                           base_kernel='predictions', kernel_transforms=[]) #[('rp', [5])])\n",
    "print(new_idxs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "operator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
