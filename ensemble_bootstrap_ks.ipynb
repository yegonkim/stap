{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does ensemble work best step-wise or trajectory-wise?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# with h5py.File(f'data_large/Burgers_train_100000_default.h5', 'r') as f:\n",
    "#     # Traj_dataset.traj_train = torch.tensor(f['train']['pde_140-256'][:10000, :131], dtype=torch.float32, device=cfg.device)\n",
    "#     traj = torch.tensor(f['train']['pde_140-256'][:1000, :131], dtype=torch.float32)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "hydra.initialize(config_path=\"cfg_long_hal\", version_base=None)\n",
    "cfg = hydra.compose(config_name=\"config\", overrides=[\"task=KS\", \"nt=14\", \"initial_datasize=64\", \"ensemble_size=5\"])\n",
    "\n",
    "from utils import set_seed\n",
    "set_seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(cfg.dataset.train_path, 'r') as f:\n",
    "    # Traj_dataset.traj_train = torch.tensor(f['train']['pde_140-256'][:10000, :131], dtype=torch.float32, device=cfg.device)\n",
    "    traj = torch.tensor(f['train']['pde_140-256'][:1000, :131], dtype=torch.float32)\n",
    "\n",
    "max = traj[:32].max()\n",
    "min = traj[:32].min()\n",
    "traj = (traj - (max + min) / 2) / (max - min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralop.models import FNO\n",
    "\n",
    "unrolling = cfg.train.unrolling\n",
    "nt = cfg.nt\n",
    "ensemble_size = cfg.ensemble_size\n",
    "num_acquire = cfg.num_acquire\n",
    "device = cfg.device\n",
    "epochs = cfg.train.epochs\n",
    "lr = cfg.train.lr\n",
    "batch_size = cfg.train.batch_size\n",
    "initial_datasize = cfg.initial_datasize\n",
    "\n",
    "def train(Y, train_nts, **kwargs):\n",
    "    model = FNO(n_modes=cfg.model.n_modes, hidden_channels=64,\n",
    "                in_channels=1, out_channels=1)\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    for b in range(Y.shape[0]):\n",
    "        for t in range(train_nts[b].item()-1):\n",
    "            inputs.append(Y[b,t])\n",
    "            outputs.append(Y[b, t+1])\n",
    "    inputs = torch.stack(inputs, dim=0).unsqueeze(1)\n",
    "    outputs = torch.stack(outputs, dim=0).unsqueeze(1)\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(inputs, outputs)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        # max_unrolling = epoch if epoch <= unrolling else unrolling\n",
    "        # unrolling_list = [r for r in range(max_unrolling + 1)]\n",
    "\n",
    "        total_loss = 0\n",
    "        for x, y in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            pred = model(x)\n",
    "            loss = criterion(pred, y)\n",
    "\n",
    "            # loss = torch.sqrt(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        scheduler.step()\n",
    "        # wandb.log({f'train/loss_{acquire_step}': total_loss})\n",
    "    return model\n",
    "\n",
    "timestep = (traj.shape[1] - 1) // (nt - 1) # 10\n",
    "Y = traj[:,0::timestep]\n",
    "train_nts = torch.ones(Y.shape[0], device=device, dtype=torch.int64)\n",
    "train_nts[:initial_datasize] = nt\n",
    "\n",
    "ensemble = [train(Y, train_nts) for _ in range(ensemble_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(0.1943), tensor(0.2186), tensor(8.9188))\n"
     ]
    }
   ],
   "source": [
    "from utils import torch_expand\n",
    "from eval_utils import compute_metrics\n",
    "\n",
    "test_Y = traj[initial_datasize:1000, 0::timestep]\n",
    "\n",
    "model = ensemble[0]\n",
    "model.eval()\n",
    "\n",
    "preds = []\n",
    "preds.append(test_Y[:,0:1]) # ensemble_size x batch x 1 x 256\n",
    "\n",
    "with torch.no_grad():\n",
    "    for t in range(nt-1):\n",
    "        X = preds[-1].to(device)\n",
    "        pred = model(X) # batch x 1 x 256\n",
    "        preds.append(pred.cpu()) # batch x 1 x 256\n",
    "\n",
    "\n",
    "preds = torch.cat(preds, dim=1) # batch x nt x 256\n",
    "pred = preds.cpu()\n",
    "\n",
    "metrics = compute_metrics(test_Y, pred, d=2, device=device, reduction=True)\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(0.1305), tensor(0.1468), tensor(4.0369))\n"
     ]
    }
   ],
   "source": [
    "from utils import torch_expand\n",
    "from eval_utils import compute_metrics\n",
    "\n",
    "test_Y = traj[initial_datasize:1000, 0::timestep]\n",
    "\n",
    "for model in ensemble:\n",
    "    model.eval()\n",
    "\n",
    "preds = []\n",
    "preds.append(torch_expand(test_Y[None,:,0:1], dim=0, copies=ensemble_size)) # ensemble_size x batch x 1 x 256\n",
    "\n",
    "with torch.no_grad():\n",
    "    for t in range(nt-1):\n",
    "        X = preds[-1].to(device)\n",
    "        pred = torch.stack([model(X[i]) for i, model in enumerate(ensemble)], dim=0) # ensemble_size x batch x 1 x 256\n",
    "        preds.append(pred.cpu())\n",
    "\n",
    "preds = torch.stack(preds, dim=1) # batch x nt x 256\n",
    "pred = preds.mean(dim=0)\n",
    "pred = pred.squeeze(2).permute(1,0,2) # batch x nt x 256\n",
    "\n",
    "metrics = compute_metrics(test_Y, pred, d=2, device=device, reduction=True)\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(0.1296), tensor(0.1458), tensor(4.4835))\n"
     ]
    }
   ],
   "source": [
    "from utils import torch_expand\n",
    "\n",
    "test_Y = traj[initial_datasize:1000, 0::timestep]\n",
    "\n",
    "for model in ensemble:\n",
    "    model.eval()\n",
    "\n",
    "preds = []\n",
    "preds.append(test_Y[:,0:1]) # ensemble_size x batch x 1 x 256\n",
    "\n",
    "with torch.no_grad():\n",
    "    for t in range(nt-1):\n",
    "        X = preds[-1].to(device)\n",
    "        pred = torch.stack([model(X) for model in ensemble], dim=0) # ensemble_size x batch x 1 x 256\n",
    "        preds.append(pred.mean(0).cpu()) # batch x 1 x 256\n",
    "\n",
    "\n",
    "preds = torch.cat(preds, dim=1) # batch x nt x 256\n",
    "pred = preds.cpu()\n",
    "\n",
    "metrics = compute_metrics(test_Y, pred, d=2, device=device, reduction=True)\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lupi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
