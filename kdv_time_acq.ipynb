{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "from neuralop.models import FNO\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "from eval_utils import compute_metrics\n",
    "\n",
    "from utils import set_seed\n",
    "# from acquisition.acquirers import select\n",
    "\n",
    "set_seed(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class Traj_dataset:\n",
    "    traj_train = None\n",
    "    traj_valid = None\n",
    "    traj_test = None\n",
    "\n",
    "\n",
    "epochs = 500\n",
    "lr = 0.001\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "def experiment_0(initial_datasize=256, num_acquire=1, device='cpu', **cfg):\n",
    "    unrolling = cfg.get('unrolling', 1)\n",
    "    nt = cfg.get('nt', 14)\n",
    "    ensemble_size = cfg.get('ensemble_size', 5)\n",
    "    selection_method = cfg.get('selection_method', 'random')\n",
    "    acquisition_function = cfg.get('acquisition_function', 'variance')\n",
    "    features = cfg.get('feature', 'direct')\n",
    "    batch_acquire = cfg.get('batch_acquire', 32)\n",
    "\n",
    "    def train(X_train, Y_train):\n",
    "        model = FNO(n_modes=cfg.model.n_modes, hidden_channels=64,\n",
    "                    in_channels=1, out_channels=1)\n",
    "\n",
    "        model = model.to(device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "        criterion = torch.nn.MSELoss()\n",
    "\n",
    "        dataset = torch.utils.data.TensorDataset(X_train, Y_train)\n",
    "        dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        model.train()\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            max_unrolling = epoch if epoch <= unrolling else unrolling\n",
    "            unrolling_list = [r for r in range(max_unrolling + 1)]\n",
    "\n",
    "            # Loop over every epoch as often as the number of timesteps in one trajectory.\n",
    "            # Since the starting point is randomly drawn, this in expectation has every possible starting point/sample combination of the training data.\n",
    "            # Therefore in expectation the whole available training information is covered.\n",
    "            total_loss = 0\n",
    "            for i in range(nt):\n",
    "                for x, y in dataloader:\n",
    "                    optimizer.zero_grad()\n",
    "                    x, y = x.to(device), y.to(device) # y has shape [batch_size, nt, nx]\n",
    "\n",
    "                    unrolled = random.choice(unrolling_list)\n",
    "                    bs = x.shape[0]\n",
    "\n",
    "                    steps = [t for t in range(0, nt - 1 - unrolled)]\n",
    "                    random_steps = random.choices(steps, k=bs)\n",
    "                    inputs = torch.stack([y[b, random_steps[b]] for b in range(bs)], dim=0).unsqueeze(1)\n",
    "                    outputs = torch.stack([y[b, random_steps[b] + unrolled+1] for b in range(bs)], dim=0).unsqueeze(1)\n",
    "\n",
    "                    # pushforward\n",
    "                    with torch.no_grad():\n",
    "                        model.eval()\n",
    "                        for _ in range(unrolled):\n",
    "                            inputs = model(inputs)\n",
    "                        model.train()\n",
    "                    \n",
    "                    pred = model(inputs)\n",
    "                    loss = criterion(pred, outputs)\n",
    "\n",
    "                    # loss = torch.sqrt(loss)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    total_loss += loss.item()\n",
    "            scheduler.step()\n",
    "        return model\n",
    "\n",
    "    def test(model):\n",
    "        X_test = Traj_dataset.traj_test[:,0,:].unsqueeze(1).to(device)\n",
    "        Y_test = Traj_dataset.traj_test[:,-1,:].unsqueeze(1).to(device)\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(X_test, Y_test)\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        model.eval()\n",
    "    \n",
    "        Y_test_pred = []\n",
    "        with torch.no_grad():\n",
    "            for x, y in testloader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                Y_test_pred.append(model(x))\n",
    "            Y_test_pred = torch.cat(Y_test_pred, dim=0).to(Y_test.device)\n",
    "        \n",
    "        metrics = compute_metrics(Y_test, Y_test_pred, d=1)\n",
    "\n",
    "        return metrics\n",
    "    \n",
    "    def test_trajectory(model):\n",
    "        X_test = Traj_dataset.traj_test[:,0,:].unsqueeze(1).to(device)\n",
    "        Y_test = Traj_dataset.traj_test[:,timestep::timestep].to(device)\n",
    "\n",
    "        testset = torch.utils.data.TensorDataset(X_test, Y_test)\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        model.eval()\n",
    "    \n",
    "        Y_test_pred = []\n",
    "        with torch.no_grad():\n",
    "            for x, y in testloader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                y_pred = model(x)\n",
    "                # print(y_pred.shape, y.shape)\n",
    "                assert y_pred.shape == y.shape\n",
    "                Y_test_pred.append(y_pred)\n",
    "            Y_test_pred = torch.cat(Y_test_pred, dim=0).to(Y_test.device)\n",
    "        \n",
    "        metrics = compute_metrics(Y_test, Y_test_pred, d=2)\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    class direct_model(torch.nn.Module):\n",
    "        def __init__(self, model, unrolling):\n",
    "            super().__init__()\n",
    "            self.model = model\n",
    "            self.unrolling = unrolling\n",
    "        def forward(self, x):\n",
    "            for _ in range(self.unrolling):\n",
    "                x = self.model(x)\n",
    "            return x\n",
    "        \n",
    "    class trajectory_model(torch.nn.Module):\n",
    "        def __init__(self, model, unrolling):\n",
    "            super().__init__()\n",
    "            self.model = model\n",
    "            self.unrolling = unrolling\n",
    "        def forward(self, x):\n",
    "            trajectory = []\n",
    "            for _ in range(self.unrolling):\n",
    "                x = self.model(x)\n",
    "                trajectory.append(x)\n",
    "            return torch.cat(trajectory, dim=1) # [batch_size, unrolling, nx]\n",
    "\n",
    "    timestep = (Traj_dataset.traj_train.shape[1] - 1) // (nt - 1) # 10\n",
    "    assert timestep == 10\n",
    "\n",
    "    X = Traj_dataset.traj_train[:,0].unsqueeze(1).to(device)\n",
    "    Y = Traj_dataset.traj_train[:,0::timestep].to(device)\n",
    "\n",
    "    train_idxs = torch.arange(initial_datasize, device=device)\n",
    "    pool_idxs = torch.arange(initial_datasize, X.shape[0], device=device)\n",
    "\n",
    "    X_train = X[train_idxs]\n",
    "    Y_train = Y[train_idxs]\n",
    "\n",
    "    X_pool = X[pool_idxs]\n",
    "\n",
    "    ensemble = [train(X_train, Y_train) for _ in tqdm(range(ensemble_size))]\n",
    "\n",
    "    results = {'datasize': [], 'rel_l2': [], 'rel_l2_trajectory': []}\n",
    "\n",
    "    results['datasize'].append(train_idxs.shape[0])\n",
    "    rel_l2_list = [test(direct_model(model, nt-1))[1].mean().item() for model in ensemble]\n",
    "    rel_l2_trajectory_list = [test_trajectory(trajectory_model(model, nt-1))[1].mean().item() for model in ensemble]\n",
    "    results['rel_l2'].append(torch.mean(torch.tensor(rel_l2_list)).item())\n",
    "    results['rel_l2_trajectory'].append(torch.mean(torch.tensor(rel_l2_trajectory_list)).item())\n",
    "    print(f'Datasize: {results[\"datasize\"][-1]}, Rel_l2: {results[\"rel_l2\"][-1]}, Rel_l2_trajectory: {results[\"rel_l2_trajectory\"][-1]}')\n",
    "\n",
    "    \n",
    "    for i in range(num_acquire):\n",
    "        if features == 'direct':\n",
    "            unrolled_ensemble = [direct_model(model, nt-1) for model in ensemble]\n",
    "        elif features == 'trajectory':\n",
    "            unrolled_ensemble = [trajectory_model(model, nt-1) for model in ensemble]\n",
    "        new_idxs = select(unrolled_ensemble, X_train, X_pool, batch_acquire, selection_method=selection_method, acquisition_function=acquisition_function, device=device)\n",
    "        # new_idxs = select_var(ensemble, X_pool, batch_acquire)\n",
    "\n",
    "        new_idxs = new_idxs.to(device)\n",
    "        # print(new_idxs)\n",
    "        # print(f'{len(new_idxs)=}')\n",
    "        logical_new_idxs = torch.zeros(pool_idxs.shape[-1], dtype=torch.bool, device=device)\n",
    "        logical_new_idxs[new_idxs] = True\n",
    "        train_idxs = torch.cat([train_idxs, pool_idxs[logical_new_idxs]], dim=-1)\n",
    "        pool_idxs = pool_idxs[~logical_new_idxs]\n",
    "\n",
    "        X_train = X[train_idxs]\n",
    "        Y_train = Y[train_idxs]\n",
    "\n",
    "        X_pool = X[pool_idxs]\n",
    "\n",
    "        ensemble = [train(X_train, Y_train) for _ in tqdm(range(ensemble_size))]\n",
    "\n",
    "        results['datasize'].append(train_idxs.shape[0])\n",
    "        rel_l2_list = [test(direct_model(model, nt-1))[1].mean().item() for model in ensemble]\n",
    "        rel_l2_trajectory_list = [test_trajectory(trajectory_model(model, nt-1))[1].mean().item() for model in ensemble]\n",
    "        results['rel_l2'].append(torch.mean(torch.tensor(rel_l2_list)).item())\n",
    "        results['rel_l2_trajectory'].append(torch.mean(torch.tensor(rel_l2_trajectory_list)).item())\n",
    "        print(f'Datasize: {results[\"datasize\"][-1]}, Rel_l2: {results[\"rel_l2\"][-1]}, Rel_l2_trajectory: {results[\"rel_l2_trajectory\"][-1]}')\n",
    "    \n",
    "    return results\n",
    "\n",
    "# EXPERIMENT_FUNCTION = {'direct': experiment_direct, 'multi': experiment_multi, 'ar_0': experiment_ar, 'ar_1': experiment_ar}\n",
    "CFG_DICT = {'direct_random': {'nt': 14, 'ensemble_size': 5, 'selection_method': 'random', 'acquisition_function': 'variance', 'feature': 'direct'},\n",
    "            'direct_variance': {'nt': 14, 'ensemble_size': 5, 'selection_method': 'greedy', 'acquisition_function': 'variance', 'feature': 'direct'},\n",
    "            'direct_lcmd': {'nt': 14, 'ensemble_size': 5, 'selection_method': 'lcmd', 'acquisition_function': 'variance', 'feature': 'direct'},\n",
    "            'trajectory_random': {'nt': 14, 'ensemble_size': 5, 'selection_method': 'random', 'acquisition_function': 'variance', 'feature': 'trajectory'},\n",
    "            'trajectory_variance': {'nt': 14, 'ensemble_size': 5, 'selection_method': 'greedy', 'acquisition_function': 'variance', 'feature': 'trajectory'},\n",
    "            'trajectory_lcmd': {'nt': 14, 'ensemble_size': 5, 'selection_method': 'lcmd', 'acquisition_function': 'variance', 'feature': 'trajectory'}}\n",
    "\n",
    "def run_experiment(experiment, equation, **cfg):\n",
    "    results = {}\n",
    "    results['experiment_name'] = experiment\n",
    "    results['equation_name'] = equation\n",
    "    cfg.update(CFG_DICT[experiment])\n",
    "\n",
    "    datasize_list = [int(datasize) for datasize in 2 ** np.linspace(5,9,5)]\n",
    "    results['initial_datasize_list'] = datasize_list\n",
    "\n",
    "    for seed in range(5):\n",
    "        print(f'Seed {seed}')\n",
    "        set_seed(seed)\n",
    "        results[seed] = {}\n",
    "        \n",
    "        for initial_datasize in datasize_list:\n",
    "            results_instance = experiment_0(initial_datasize=initial_datasize, num_acquire=1, device=device, **cfg)\n",
    "            results[seed][initial_datasize] = results_instance\n",
    "        print(results[seed])\n",
    "\n",
    "    return results\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Run experiment of your choice\")\n",
    "    parser.add_argument(\"--equation\", choices=[\"KdV\", \"Burgers\", \"KS\"], default=\"KdV\")\n",
    "    parser.add_argument(\"--experiment\", choices=[\"direct_random\", \"direct_variance\", \"direct_lcmd\", \"trajectory_random\", \"trajectory_variance\", \"trajectory_lcmd\"], default=\"direct_random\")\n",
    "    parser.add_argument(\"--unrolling\", type=int, default=1)\n",
    "    parser.add_argument(\"--batch_acquire\", type=int, default=32)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    with h5py.File(f'data/{args.equation}_train_1024_default.h5', 'r') as f:\n",
    "        Traj_dataset.traj_train = torch.tensor(f['train']['pde_140-256'][:], dtype=torch.float32)[:, :131]\n",
    "    with h5py.File(f'data/{args.equation}_valid_1024_default.h5', 'r') as f:\n",
    "        Traj_dataset.traj_valid = torch.tensor(f['valid']['pde_140-256'][:], dtype=torch.float32)[:, :131]\n",
    "    with h5py.File(f'data/{args.equation}_test_4096_default.h5', 'r') as f:\n",
    "        Traj_dataset.traj_test = torch.tensor(f['test']['pde_140-256'][:], dtype=torch.float32)[:, :131]\n",
    "\n",
    "    results = run_experiment(args.experiment, args.equation, unrolling=args.unrolling, batch_acquire=args.batch_acquire)\n",
    "\n",
    "    print(results)\n",
    "    save_path = get_results_path() + f'/results_al_{args.equation}_{args.experiment}_{args.batch_acquire}_{time.strftime(\"%Y%m%d-%H%M%S\")}.pt'\n",
    "    torch.save(results, save_path)\n",
    "    print(f'Results saved to {save_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "class args:\n",
    "    equation = 'KdV'\n",
    "\n",
    "with h5py.File(f'data/{args.equation}_train_1024_default.h5', 'r') as f:\n",
    "    Traj_dataset.traj_train = torch.tensor(f['train']['pde_140-256'][:], dtype=torch.float32)[:, :131]\n",
    "with h5py.File(f'data/{args.equation}_valid_1024_default.h5', 'r') as f:\n",
    "    Traj_dataset.traj_valid = torch.tensor(f['valid']['pde_140-256'][:], dtype=torch.float32)[:, :131]\n",
    "with h5py.File(f'data/{args.equation}_test_4096_default.h5', 'r') as f:\n",
    "    Traj_dataset.traj_test = torch.tensor(f['test']['pde_140-256'][:], dtype=torch.float32)[:, :131]\n",
    "\n",
    "epochs = 500\n",
    "# experiment_0(256, 1, device=device, unrolling=1, nt=14, ensemble_size=5, selection_method='stochastic', feature='direct', batch_acquire=1)\n",
    "experiment_0(64, 1, device=device, unrolling=1, nt=14, ensemble_size=2, selection_method='random', feature='direct', batch_acquire=32)\n",
    "experiment_0(64, 1, device=device, unrolling=1, nt=14, ensemble_size=2, selection_method='variance', feature='direct', batch_acquire=32)\n",
    "experiment_0(64, 1, device=device, unrolling=1, nt=14, ensemble_size=2, selection_method='stochastic', feature='direct', batch_acquire=32)\n",
    "experiment_0(64, 1, device=device, unrolling=1, nt=14, ensemble_size=2, selection_method='lcmd', feature='direct', batch_acquire=32)\n",
    "experiment_0(64, 1, device=device, unrolling=1, nt=14, ensemble_size=2, selection_method='lcmd_shared', feature='direct', batch_acquire=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "operator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
