{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing same model for every time step vs different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Loading test data...\n",
      "Datasize: 1664, L2: 0.5233489871025085, Rel_l2: 0.12047380208969116, MSE: 0.08471187204122543\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "from neuralop.models import FNO\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "from eval_utils import compute_metrics\n",
    "\n",
    "from utils import set_seed, flatten_configdict\n",
    "from acquisition.acquirers import select, select_time\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "import hydra\n",
    "import wandb\n",
    "\n",
    "\n",
    "class Traj_dataset:\n",
    "    traj_train = None\n",
    "    traj_valid = None\n",
    "    traj_test = None\n",
    "\n",
    "class cfg:\n",
    "    equation = 'KdV'\n",
    "\n",
    "\n",
    "device = 'cuda'\n",
    "nt = 14\n",
    "\n",
    "lr = 1e-3\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "unrolling = 0\n",
    "initial_time_steps = 1664\n",
    "\n",
    "print('Loading training data...')\n",
    "with h5py.File(f'data_large/{cfg.equation}_train_100000_default.h5', 'r') as f:\n",
    "    # Traj_dataset.traj_train = torch.tensor(f['train']['pde_140-256'][:10000, :131], dtype=torch.float32, device=cfg.device)\n",
    "    Traj_dataset.traj_train = torch.tensor(f['train']['pde_140-256'][:1000, :131], dtype=torch.float32)\n",
    "    # Traj_dataset.traj_train = torch.tensor(f['train']['pde_140-256'][:100, :131], dtype=torch.float32, device=cfg.device)\n",
    "# print('Loading validation data...')\n",
    "# with h5py.File(f'data_large/{cfg.equation}_valid_1024_default.h5', 'r') as f:\n",
    "#     Traj_dataset.traj_valid = torch.tensor(f['valid']['pde_140-256'][:, :131], dtype=torch.float32)\n",
    "print('Loading test data...')\n",
    "with h5py.File(f'data_large/{cfg.equation}_test_100000_default.h5', 'r') as f:\n",
    "    # Traj_dataset.traj_test = torch.tensor(f['test']['pde_140-256'][:, :131], dtype=torch.float32)\n",
    "    Traj_dataset.traj_test = torch.tensor(f['test']['pde_140-256'][:10000, :131], dtype=torch.float32)\n",
    "\n",
    "\n",
    "def train(Y, train_nts, **kwargs):\n",
    "    assert unrolling == 0\n",
    "\n",
    "    acquire_step = kwargs.get('acquire_step', 0)\n",
    "\n",
    "    model = FNO(n_modes=cfg.model.n_modes, hidden_channels=64,\n",
    "                in_channels=1, out_channels=1)\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    for b in range(Y.shape[0]):\n",
    "        for t in range(train_nts[b].item()-1):\n",
    "            inputs.append(Y[b,t])\n",
    "            outputs.append(Y[b, t+1])\n",
    "    inputs = torch.stack(inputs, dim=0).unsqueeze(1)\n",
    "    outputs = torch.stack(outputs, dim=0).unsqueeze(1)\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(inputs, outputs)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        # max_unrolling = epoch if epoch <= unrolling else unrolling\n",
    "        # unrolling_list = [r for r in range(max_unrolling + 1)]\n",
    "\n",
    "        total_loss = 0\n",
    "        for x, y in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            pred = model(x)\n",
    "            loss = criterion(pred, y)\n",
    "\n",
    "            # loss = torch.sqrt(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        scheduler.step()\n",
    "    return model\n",
    "\n",
    "def test(model):\n",
    "    X_test = Traj_dataset.traj_test[:,0,:].unsqueeze(1).to(device)\n",
    "    Y_test = Traj_dataset.traj_test[:,-1,:].unsqueeze(1).to(device)\n",
    "\n",
    "    testset = torch.utils.data.TensorDataset(X_test, Y_test)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    Y_test_pred = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in testloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            Y_test_pred.append(model(x))\n",
    "        Y_test_pred = torch.cat(Y_test_pred, dim=0).to(device)\n",
    "    \n",
    "    metrics = compute_metrics(Y_test, Y_test_pred, d=1)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def test_trajectory(model):\n",
    "    X_test = Traj_dataset.traj_test[:,0].unsqueeze(1).to(device)\n",
    "    Y_test = Traj_dataset.traj_test[:,timestep::timestep].to(device)\n",
    "\n",
    "    testset = torch.utils.data.TensorDataset(X_test, Y_test)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    Y_test_pred = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in testloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_pred = model(x)\n",
    "            # print(y_pred.shape, y.shape)\n",
    "            assert y_pred.shape == y.shape\n",
    "            Y_test_pred.append(y_pred)\n",
    "        Y_test_pred = torch.cat(Y_test_pred, dim=0).to(device)\n",
    "    \n",
    "    metrics = compute_metrics(Y_test, Y_test_pred, d=2)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "class direct_model(torch.nn.Module):\n",
    "    def __init__(self, model, unrolling):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.unrolling = unrolling\n",
    "    def forward(self, x):\n",
    "        for _ in range(self.unrolling):\n",
    "            x = self.model(x)\n",
    "        return x\n",
    "    \n",
    "class trajectory_model(torch.nn.Module):\n",
    "    def __init__(self, model, unrolling):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.unrolling = unrolling\n",
    "    def forward(self, x):\n",
    "        trajectory = []\n",
    "        for _ in range(self.unrolling):\n",
    "            x = self.model(x)\n",
    "            trajectory.append(x)\n",
    "        return torch.cat(trajectory, dim=1) # [cfg.train.batch_size, unrolling, nx]\n",
    "\n",
    "timestep = (Traj_dataset.traj_train.shape[1] - 1) // (nt - 1) # 10\n",
    "assert timestep == 10 # hardcoded for now (130/ (14-1) = 10)\n",
    "\n",
    "X = Traj_dataset.traj_train[:,0].unsqueeze(1).to(device)\n",
    "Y = Traj_dataset.traj_train[:,0::timestep].to(device)\n",
    "\n",
    "train_nts = torch.ones(X.shape[0], device=device, dtype=torch.int64)\n",
    "# values are between 1 and 14, inclusive\n",
    "# 1 means only initial data, 14 means all data\n",
    "\n",
    "train_nts[:initial_time_steps//(nt-1)] = nt\n",
    "if initial_time_steps % (nt-1) != 0:\n",
    "    train_nts[initial_time_steps//(nt-1)] = initial_time_steps % (nt-1)\n",
    "\n",
    "# train_idxs = torch.arange(initial_datasize, device=device)\n",
    "# pool_idxs = torch.arange(initial_datasize, X.shape[0], device=device)\n",
    "\n",
    "# X_train = X[train_idxs]\n",
    "# Y_train = Y[train_idxs]\n",
    "\n",
    "# X_pool = X[pool_idxs]\n",
    "\n",
    "model = train(Y, train_nts, acquire_step=0)\n",
    "\n",
    "results = {'datasize': [], 'l2': [], 'rel_l2': [], 'mse': []}\n",
    "\n",
    "results['datasize'].append((train_nts-1).sum().item())\n",
    "# rel_l2_list = [test(direct_model(model, nt-1))[1].mean().item() for model in ensemble]\n",
    "metrics_list = torch.stack(test_trajectory(trajectory_model(model, nt-1))) # [3, datasize]\n",
    "results['l2'].append(metrics_list[0, :].mean().item())\n",
    "results['rel_l2'].append(metrics_list[1, :].mean().item())\n",
    "results['mse'].append(metrics_list[2, :].mean().item())\n",
    "print(f'Datasize: {results[\"datasize\"][-1]}, L2: {results[\"l2\"][-1]}, Rel_l2: {results[\"rel_l2\"][-1]}, MSE: {results[\"mse\"][-1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Loading test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [01:44<00:00,  8.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasize: 1664, L2: 1.867620825767517, Rel_l2: 0.5719999074935913, MSE: 0.29869818687438965\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "from neuralop.models import FNO\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "from eval_utils import compute_metrics\n",
    "\n",
    "from utils import set_seed, flatten_configdict\n",
    "from acquisition.acquirers import select, select_time\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "import hydra\n",
    "import wandb\n",
    "\n",
    "\n",
    "class Traj_dataset:\n",
    "    traj_train = None\n",
    "    traj_valid = None\n",
    "    traj_test = None\n",
    "\n",
    "class cfg:\n",
    "    equation = 'KdV'\n",
    "\n",
    "\n",
    "device = 'cuda'\n",
    "nt = 14\n",
    "\n",
    "lr = 1e-3\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "unrolling = 0\n",
    "initial_time_steps = 1664\n",
    "\n",
    "print('Loading training data...')\n",
    "with h5py.File(f'data_large/{cfg.equation}_train_100000_default.h5', 'r') as f:\n",
    "    # Traj_dataset.traj_train = torch.tensor(f['train']['pde_140-256'][:10000, :131], dtype=torch.float32, device=cfg.device)\n",
    "    Traj_dataset.traj_train = torch.tensor(f['train']['pde_140-256'][:1000, :131], dtype=torch.float32)\n",
    "    # Traj_dataset.traj_train = torch.tensor(f['train']['pde_140-256'][:100, :131], dtype=torch.float32, device=cfg.device)\n",
    "# print('Loading validation data...')\n",
    "# with h5py.File(f'data_large/{cfg.equation}_valid_1024_default.h5', 'r') as f:\n",
    "#     Traj_dataset.traj_valid = torch.tensor(f['valid']['pde_140-256'][:, :131], dtype=torch.float32)\n",
    "print('Loading test data...')\n",
    "with h5py.File(f'data_large/{cfg.equation}_test_100000_default.h5', 'r') as f:\n",
    "    # Traj_dataset.traj_test = torch.tensor(f['test']['pde_140-256'][:, :131], dtype=torch.float32)\n",
    "    Traj_dataset.traj_test = torch.tensor(f['test']['pde_140-256'][:10000, :131], dtype=torch.float32)\n",
    "\n",
    "\n",
    "def train(Y, train_nts, **kwargs):\n",
    "    assert unrolling == 0\n",
    "\n",
    "    acquire_step = kwargs.get('acquire_step', 0)\n",
    "\n",
    "    models = [FNO(n_modes=cfg.model.n_modes, hidden_channels=64,\n",
    "                in_channels=1, out_channels=1) for _ in range(nt-1)]\n",
    "\n",
    "    for t, model in tqdm(enumerate(models), total=nt-1):\n",
    "        model.to(device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "        criterion = torch.nn.MSELoss()\n",
    "\n",
    "        inputs = []\n",
    "        outputs = []\n",
    "        for b in range(Y.shape[0]):\n",
    "            if t < train_nts[b].item()-1:\n",
    "                inputs.append(Y[b,t])\n",
    "                outputs.append(Y[b, t+1])\n",
    "        inputs = torch.stack(inputs, dim=0).unsqueeze(1)\n",
    "        outputs = torch.stack(outputs, dim=0).unsqueeze(1)\n",
    "\n",
    "        dataset = torch.utils.data.TensorDataset(inputs, outputs)\n",
    "        dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            # max_unrolling = epoch if epoch <= unrolling else unrolling\n",
    "            # unrolling_list = [r for r in range(max_unrolling + 1)]\n",
    "\n",
    "            total_loss = 0\n",
    "            for x, y in dataloader:\n",
    "                optimizer.zero_grad()\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                \n",
    "                pred = model(x)\n",
    "                loss = criterion(pred, y)\n",
    "\n",
    "                # loss = torch.sqrt(loss)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "            scheduler.step()\n",
    "            \n",
    "    return models\n",
    "\n",
    "def test_trajectory(model):\n",
    "    X_test = Traj_dataset.traj_test[:,0].unsqueeze(1).to(device)\n",
    "    Y_test = Traj_dataset.traj_test[:,timestep::timestep].to(device)\n",
    "\n",
    "    testset = torch.utils.data.TensorDataset(X_test, Y_test)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    Y_test_pred = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in testloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_pred = model(x)\n",
    "            # print(y_pred.shape, y.shape)\n",
    "            assert y_pred.shape == y.shape\n",
    "            Y_test_pred.append(y_pred)\n",
    "        Y_test_pred = torch.cat(Y_test_pred, dim=0).to(device)\n",
    "    \n",
    "    metrics = compute_metrics(Y_test, Y_test_pred, d=2)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# class direct_model(torch.nn.Module):\n",
    "#     def __init__(self, model, unrolling):\n",
    "#         super().__init__()\n",
    "#         self.model = model\n",
    "#         self.unrolling = unrolling\n",
    "#     def forward(self, x):\n",
    "#         for _ in range(self.unrolling):\n",
    "#             x = self.model(x)\n",
    "#         return x\n",
    "    \n",
    "class trajectory_model(torch.nn.Module):\n",
    "    def __init__(self, models):\n",
    "        super().__init__()\n",
    "        self.models = models\n",
    "    def forward(self, x):\n",
    "        trajectory = []\n",
    "        for model in self.models:\n",
    "            x = model(x)\n",
    "            trajectory.append(x)\n",
    "        return torch.cat(trajectory, dim=1) # [cfg.train.batch_size, unrolling, nx]\n",
    "    def eval(self):\n",
    "        for model in self.models:\n",
    "            model.eval()\n",
    "\n",
    "timestep = (Traj_dataset.traj_train.shape[1] - 1) // (nt - 1) # 10\n",
    "assert timestep == 10 # hardcoded for now (130/ (14-1) = 10)\n",
    "\n",
    "X = Traj_dataset.traj_train[:,0].unsqueeze(1).to(device)\n",
    "Y = Traj_dataset.traj_train[:,0::timestep].to(device)\n",
    "\n",
    "train_nts = torch.ones(X.shape[0], device=device, dtype=torch.int64)\n",
    "# values are between 1 and 14, inclusive\n",
    "# 1 means only initial data, 14 means all data\n",
    "\n",
    "train_nts[:initial_time_steps//(nt-1)] = nt\n",
    "if initial_time_steps % (nt-1) != 0:\n",
    "    train_nts[initial_time_steps//(nt-1)] = initial_time_steps % (nt-1)\n",
    "\n",
    "# train_idxs = torch.arange(initial_datasize, device=device)\n",
    "# pool_idxs = torch.arange(initial_datasize, X.shape[0], device=device)\n",
    "\n",
    "# X_train = X[train_idxs]\n",
    "# Y_train = Y[train_idxs]\n",
    "\n",
    "# X_pool = X[pool_idxs]\n",
    "\n",
    "models = train(Y, train_nts, acquire_step=0)\n",
    "\n",
    "results = {'datasize': [], 'l2': [], 'rel_l2': [], 'mse': []}\n",
    "\n",
    "results['datasize'].append((train_nts-1).sum().item())\n",
    "# rel_l2_list = [test(direct_model(model, nt-1))[1].mean().item() for model in ensemble]\n",
    "metrics_list = torch.stack(test_trajectory(trajectory_model(models))) # [3, datasize]\n",
    "results['l2'].append(metrics_list[0, :].mean().item())\n",
    "results['rel_l2'].append(metrics_list[1, :].mean().item())\n",
    "results['mse'].append(metrics_list[2, :].mean().item())\n",
    "print(f'Datasize: {results[\"datasize\"][-1]}, L2: {results[\"l2\"][-1]}, Rel_l2: {results[\"rel_l2\"][-1]}, MSE: {results[\"mse\"][-1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Loading test data...\n",
      "Datasize: 1664, L2: 2.91375994682312, Rel_l2: 90456912.0, MSE: 0.41966328024864197\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "from neuralop.models import FNO\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "from eval_utils import compute_metrics\n",
    "\n",
    "from utils import set_seed, flatten_configdict\n",
    "from acquisition.acquirers import select, select_time\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "import hydra\n",
    "import wandb\n",
    "\n",
    "\n",
    "class Traj_dataset:\n",
    "    traj_train = None\n",
    "    traj_valid = None\n",
    "    traj_test = None\n",
    "\n",
    "class cfg:\n",
    "    equation = 'KdV'\n",
    "\n",
    "\n",
    "device = 'cuda'\n",
    "nt = 14\n",
    "\n",
    "lr = 1e-3\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "unrolling = 0\n",
    "initial_time_steps = 1664\n",
    "\n",
    "print('Loading training data...')\n",
    "with h5py.File(f'data_large/{cfg.equation}_train_100000_default.h5', 'r') as f:\n",
    "    # Traj_dataset.traj_train = torch.tensor(f['train']['pde_140-256'][:10000, :131], dtype=torch.float32, device=cfg.device)\n",
    "    Traj_dataset.traj_train = torch.tensor(f['train']['pde_140-256'][:1000, :131], dtype=torch.float32)\n",
    "    # Traj_dataset.traj_train = torch.tensor(f['train']['pde_140-256'][:100, :131], dtype=torch.float32, device=cfg.device)\n",
    "# print('Loading validation data...')\n",
    "# with h5py.File(f'data_large/{cfg.equation}_valid_1024_default.h5', 'r') as f:\n",
    "#     Traj_dataset.traj_valid = torch.tensor(f['valid']['pde_140-256'][:, :131], dtype=torch.float32)\n",
    "print('Loading test data...')\n",
    "with h5py.File(f'data_large/{cfg.equation}_test_100000_default.h5', 'r') as f:\n",
    "    # Traj_dataset.traj_test = torch.tensor(f['test']['pde_140-256'][:, :131], dtype=torch.float32)\n",
    "    Traj_dataset.traj_test = torch.tensor(f['test']['pde_140-256'][:10000, :131], dtype=torch.float32)\n",
    "\n",
    "\n",
    "def train(Y, train_nts, **kwargs):\n",
    "    assert unrolling == 0\n",
    "\n",
    "    acquire_step = kwargs.get('acquire_step', 0)\n",
    "\n",
    "    model = FNO(n_modes=cfg.model.n_modes, hidden_channels=64,\n",
    "                in_channels=1, out_channels=1)\n",
    "    \n",
    "    model = direct_model(model, nt-1)\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    for b in range(Y.shape[0]):\n",
    "        if train_nts[b].item() > 1:\n",
    "            inputs.append(Y[b,0])\n",
    "            outputs.append(Y[b, -1])\n",
    "    inputs = torch.stack(inputs, dim=0).unsqueeze(1)\n",
    "    outputs = torch.stack(outputs, dim=0).unsqueeze(1)\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(inputs, outputs)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        # max_unrolling = epoch if epoch <= unrolling else unrolling\n",
    "        # unrolling_list = [r for r in range(max_unrolling + 1)]\n",
    "\n",
    "        total_loss = 0\n",
    "        for x, y in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            pred = model(x)\n",
    "            loss = criterion(pred, y)\n",
    "\n",
    "            # loss = torch.sqrt(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        scheduler.step()\n",
    "    return model\n",
    "\n",
    "def test(model):\n",
    "    X_test = Traj_dataset.traj_test[:,0,:].unsqueeze(1).to(device)\n",
    "    Y_test = Traj_dataset.traj_test[:,-1,:].unsqueeze(1).to(device)\n",
    "\n",
    "    testset = torch.utils.data.TensorDataset(X_test, Y_test)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    Y_test_pred = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in testloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            Y_test_pred.append(model(x))\n",
    "        Y_test_pred = torch.cat(Y_test_pred, dim=0).to(device)\n",
    "    \n",
    "    metrics = compute_metrics(Y_test, Y_test_pred, d=1)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def test_trajectory(model):\n",
    "    X_test = Traj_dataset.traj_test[:,0].unsqueeze(1).to(device)\n",
    "    Y_test = Traj_dataset.traj_test[:,timestep::timestep].to(device)\n",
    "\n",
    "    testset = torch.utils.data.TensorDataset(X_test, Y_test)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    Y_test_pred = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in testloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_pred = model(x)\n",
    "            # print(y_pred.shape, y.shape)\n",
    "            assert y_pred.shape == y.shape\n",
    "            Y_test_pred.append(y_pred)\n",
    "        Y_test_pred = torch.cat(Y_test_pred, dim=0).to(device)\n",
    "    \n",
    "    metrics = compute_metrics(Y_test, Y_test_pred, d=2)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "class direct_model(torch.nn.Module):\n",
    "    def __init__(self, model, unrolling):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.unrolling = unrolling\n",
    "    def forward(self, x):\n",
    "        for _ in range(self.unrolling):\n",
    "            x = self.model(x)\n",
    "        return x\n",
    "    \n",
    "class trajectory_model(torch.nn.Module):\n",
    "    def __init__(self, model, unrolling):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.unrolling = unrolling\n",
    "    def forward(self, x):\n",
    "        trajectory = []\n",
    "        for _ in range(self.unrolling):\n",
    "            x = self.model(x)\n",
    "            trajectory.append(x)\n",
    "        return torch.cat(trajectory, dim=1) # [cfg.train.batch_size, unrolling, nx]\n",
    "\n",
    "timestep = (Traj_dataset.traj_train.shape[1] - 1) // (nt - 1) # 10\n",
    "assert timestep == 10 # hardcoded for now (130/ (14-1) = 10)\n",
    "\n",
    "X = Traj_dataset.traj_train[:,0].unsqueeze(1).to(device)\n",
    "Y = Traj_dataset.traj_train[:,0::timestep].to(device)\n",
    "\n",
    "train_nts = torch.ones(X.shape[0], device=device, dtype=torch.int64)\n",
    "# values are between 1 and 14, inclusive\n",
    "# 1 means only initial data, 14 means all data\n",
    "\n",
    "train_nts[:initial_time_steps//(nt-1)] = nt\n",
    "if initial_time_steps % (nt-1) != 0:\n",
    "    train_nts[initial_time_steps//(nt-1)] = initial_time_steps % (nt-1)\n",
    "\n",
    "# train_idxs = torch.arange(initial_datasize, device=device)\n",
    "# pool_idxs = torch.arange(initial_datasize, X.shape[0], device=device)\n",
    "\n",
    "# X_train = X[train_idxs]\n",
    "# Y_train = Y[train_idxs]\n",
    "\n",
    "# X_pool = X[pool_idxs]\n",
    "\n",
    "model = train(Y, train_nts, acquire_step=0)\n",
    "\n",
    "results = {'datasize': [], 'l2': [], 'rel_l2': [], 'mse': []}\n",
    "\n",
    "results['datasize'].append((train_nts-1).sum().item())\n",
    "# rel_l2_list = [test(direct_model(model, nt-1))[1].mean().item() for model in ensemble]\n",
    "metrics_list = torch.stack(test_trajectory(trajectory_model(model, nt-1))) # [3, datasize]\n",
    "results['l2'].append(metrics_list[0, :].mean().item())\n",
    "results['rel_l2'].append(metrics_list[1, :].mean().item())\n",
    "results['mse'].append(metrics_list[2, :].mean().item())\n",
    "print(f'Datasize: {results[\"datasize\"][-1]}, L2: {results[\"l2\"][-1]}, Rel_l2: {results[\"rel_l2\"][-1]}, MSE: {results[\"mse\"][-1]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "from neuralop.models import FNO\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "from eval_utils import compute_metrics\n",
    "\n",
    "from utils import set_seed, flatten_configdict\n",
    "from acquisition.acquirers import select, select_time\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "import hydra\n",
    "import wandb\n",
    "\n",
    "\n",
    "class Traj_dataset:\n",
    "    traj_train = None\n",
    "    traj_valid = None\n",
    "    traj_test = None\n",
    "\n",
    "class cfg:\n",
    "    equation = 'KdV'\n",
    "\n",
    "\n",
    "device = 'cuda'\n",
    "nt = 14\n",
    "\n",
    "lr = 1e-3\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "unrolling = 0\n",
    "initial_time_steps = 1664\n",
    "\n",
    "print('Loading training data...')\n",
    "with h5py.File(f'data_large/{cfg.equation}_train_100000_default.h5', 'r') as f:\n",
    "    # Traj_dataset.traj_train = torch.tensor(f['train']['pde_140-256'][:10000, :131], dtype=torch.float32, device=cfg.device)\n",
    "    Traj_dataset.traj_train = torch.tensor(f['train']['pde_140-256'][:1000, :131], dtype=torch.float32)\n",
    "    # Traj_dataset.traj_train = torch.tensor(f['train']['pde_140-256'][:100, :131], dtype=torch.float32, device=cfg.device)\n",
    "# print('Loading validation data...')\n",
    "# with h5py.File(f'data_large/{cfg.equation}_valid_1024_default.h5', 'r') as f:\n",
    "#     Traj_dataset.traj_valid = torch.tensor(f['valid']['pde_140-256'][:, :131], dtype=torch.float32)\n",
    "print('Loading test data...')\n",
    "with h5py.File(f'data_large/{cfg.equation}_test_100000_default.h5', 'r') as f:\n",
    "    # Traj_dataset.traj_test = torch.tensor(f['test']['pde_140-256'][:, :131], dtype=torch.float32)\n",
    "    Traj_dataset.traj_test = torch.tensor(f['test']['pde_140-256'][:10000, :131], dtype=torch.float32)\n",
    "\n",
    "\n",
    "def train(Y, train_nts, **kwargs):\n",
    "    assert unrolling == 0\n",
    "\n",
    "    acquire_step = kwargs.get('acquire_step', 0)\n",
    "\n",
    "    model = FNO(n_modes=cfg.model.n_modes, hidden_channels=64,\n",
    "                in_channels=1, out_channels=1)\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    for b in range(Y.shape[0]):\n",
    "        if train_nts[b].item() > 1:\n",
    "            inputs.append(Y[b,0])\n",
    "            outputs.append(Y[b, -1])\n",
    "    inputs = torch.stack(inputs, dim=0).unsqueeze(1)\n",
    "    outputs = torch.stack(outputs, dim=0).unsqueeze(1)\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(inputs, outputs)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        # max_unrolling = epoch if epoch <= unrolling else unrolling\n",
    "        # unrolling_list = [r for r in range(max_unrolling + 1)]\n",
    "\n",
    "        total_loss = 0\n",
    "        for x, y in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            pred = model(x)\n",
    "            loss = criterion(pred, y)\n",
    "\n",
    "            # loss = torch.sqrt(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        scheduler.step()\n",
    "    return model\n",
    "\n",
    "def test(model):\n",
    "    X_test = Traj_dataset.traj_test[:,0,:].unsqueeze(1).to(device)\n",
    "    Y_test = Traj_dataset.traj_test[:,-1,:].unsqueeze(1).to(device)\n",
    "\n",
    "    testset = torch.utils.data.TensorDataset(X_test, Y_test)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    Y_test_pred = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in testloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            Y_test_pred.append(model(x))\n",
    "        Y_test_pred = torch.cat(Y_test_pred, dim=0).to(device)\n",
    "    \n",
    "    metrics = compute_metrics(Y_test, Y_test_pred, d=1)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def test_trajectory(model):\n",
    "    X_test = Traj_dataset.traj_test[:,0].unsqueeze(1).to(device)\n",
    "    Y_test = Traj_dataset.traj_test[:,timestep::timestep].to(device)\n",
    "\n",
    "    testset = torch.utils.data.TensorDataset(X_test, Y_test)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    Y_test_pred = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in testloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_pred = model(x)\n",
    "            # print(y_pred.shape, y.shape)\n",
    "            assert y_pred.shape == y.shape\n",
    "            Y_test_pred.append(y_pred)\n",
    "        Y_test_pred = torch.cat(Y_test_pred, dim=0).to(device)\n",
    "    \n",
    "    metrics = compute_metrics(Y_test, Y_test_pred, d=2)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "class direct_model(torch.nn.Module):\n",
    "    def __init__(self, model, unrolling):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.unrolling = unrolling\n",
    "    def forward(self, x):\n",
    "        for _ in range(self.unrolling):\n",
    "            x = self.model(x)\n",
    "        return x\n",
    "    \n",
    "class trajectory_model(torch.nn.Module):\n",
    "    def __init__(self, model, unrolling):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.unrolling = unrolling\n",
    "    def forward(self, x):\n",
    "        trajectory = []\n",
    "        for _ in range(self.unrolling):\n",
    "            x = self.model(x)\n",
    "            trajectory.append(x)\n",
    "        return torch.cat(trajectory, dim=1) # [cfg.train.batch_size, unrolling, nx]\n",
    "\n",
    "timestep = (Traj_dataset.traj_train.shape[1] - 1) // (nt - 1) # 10\n",
    "assert timestep == 10 # hardcoded for now (130/ (14-1) = 10)\n",
    "\n",
    "X = Traj_dataset.traj_train[:,0].unsqueeze(1).to(device)\n",
    "Y = Traj_dataset.traj_train[:,0::timestep].to(device)\n",
    "\n",
    "train_nts = torch.ones(X.shape[0], device=device, dtype=torch.int64)\n",
    "# values are between 1 and 14, inclusive\n",
    "# 1 means only initial data, 14 means all data\n",
    "\n",
    "train_nts[:initial_time_steps//(nt-1)] = nt\n",
    "if initial_time_steps % (nt-1) != 0:\n",
    "    train_nts[initial_time_steps//(nt-1)] = initial_time_steps % (nt-1)\n",
    "\n",
    "# train_idxs = torch.arange(initial_datasize, device=device)\n",
    "# pool_idxs = torch.arange(initial_datasize, X.shape[0], device=device)\n",
    "\n",
    "# X_train = X[train_idxs]\n",
    "# Y_train = Y[train_idxs]\n",
    "\n",
    "# X_pool = X[pool_idxs]\n",
    "\n",
    "model = train(Y, train_nts, acquire_step=0)\n",
    "\n",
    "results = {'datasize': [], 'l2': [], 'rel_l2': [], 'mse': []}\n",
    "\n",
    "results['datasize'].append((train_nts-1).sum().item())\n",
    "# rel_l2_list = [test(direct_model(model, nt-1))[1].mean().item() for model in ensemble]\n",
    "metrics_list = torch.stack(test_trajectory(trajectory_model(model, nt-1))) # [3, datasize]\n",
    "results['l2'].append(metrics_list[0, :].mean().item())\n",
    "results['rel_l2'].append(metrics_list[1, :].mean().item())\n",
    "results['mse'].append(metrics_list[2, :].mean().item())\n",
    "print(f'Datasize: {results[\"datasize\"][-1]}, L2: {results[\"l2\"][-1]}, Rel_l2: {results[\"rel_l2\"][-1]}, MSE: {results[\"mse\"][-1]}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lupi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
